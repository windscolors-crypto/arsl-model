<!DOCTYPE html>
<html lang="ar" dir="rtl">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>SignVerse - لغة الإشارة العربية</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.22.0"></script>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }

        body {
            font-family: 'Segoe UI', Tahoma, sans-serif;
            background: #0f0f23;
            color: #fff;
            min-height: 100vh;
            display: flex;
            flex-direction: column;
            align-items: center;
        }

        .header {
            text-align: center;
            padding: 12px;
            width: 100%;
            background: linear-gradient(135deg, #667eea, #764ba2);
        }

        .header h1 { font-size: 1.4rem; }
        .header p { font-size: 0.75rem; opacity: 0.85; margin-top: 2px; }

        .camera-box {
            position: relative;
            width: 90%;
            max-width: 380px;
            margin: 12px auto;
            border-radius: 16px;
            overflow: hidden;
            border: 3px solid #667eea;
        }

        .camera-box.detecting {
            border-color: #44cc44;
            box-shadow: 0 0 20px rgba(68, 204, 68, 0.3);
        }

        #video {
            width: 100%;
            display: block;
            transform: scaleX(-1);
        }

        #canvas { display: none; }

        .result {
            width: 90%;
            max-width: 380px;
            margin: 10px auto;
            padding: 20px;
            background: #1a1a35;
            border-radius: 16px;
            text-align: center;
            border: 2px solid #333;
        }

        .result-letter {
            font-size: 4rem;
            font-weight: bold;
            color: #667eea;
            min-height: 80px;
            display: flex;
            align-items: center;
            justify-content: center;
        }

        .result-confidence {
            font-size: 0.9rem;
            color: #aaa;
            margin-top: 5px;
        }

        .sentence-box {
            width: 90%;
            max-width: 380px;
            margin: 8px auto;
            padding: 15px;
            background: #1a1a35;
            border-radius: 12px;
            text-align: center;
            border: 2px solid #333;
            min-height: 50px;
        }

        .sentence-text {
            font-size: 1.5rem;
            color: #e0e0ff;
            letter-spacing: 4px;
            direction: rtl;
        }

        .buttons {
            display: flex;
            gap: 8px;
            margin: 10px auto;
            width: 90%;
            max-width: 380px;
        }

        .btn {
            flex: 1;
            padding: 12px;
            border: none;
            border-radius: 12px;
            font-size: 0.9rem;
            font-weight: bold;
            cursor: pointer;
            transition: transform 0.2s;
        }

        .btn:active { transform: scale(0.95); }

        .btn-auto {
            background: linear-gradient(135deg, #44cc44, #22aa22);
            color: #fff;
        }

        .btn-auto.paused {
            background: linear-gradient(135deg, #667eea, #764ba2);
        }

        .btn-add {
            background: linear-gradient(135deg, #667eea, #764ba2);
            color: #fff;
        }

        .btn-clear {
            background: #333;
            color: #fff;
        }

        .btn-delete {
            background: #cc3333;
            color: #fff;
            flex: 0.5;
        }

        .status {
            text-align: center;
            padding: 8px;
            font-size: 0.85rem;
            color: #aaa;
        }

        .status.loading { color: #ffaa00; }
        .status.ready { color: #44cc44; }
        .status.error { color: #cc4444; }

        .mode-info {
            width: 90%;
            max-width: 380px;
            margin: 4px auto;
            padding: 8px;
            border-radius: 8px;
            font-size: 0.8rem;
            text-align: center;
            background: #1a3a1a;
            color: #44cc44;
        }

        .mode-info.paused {
            background: #1a1a35;
            color: #888;
        }

        .instructions {
            width: 90%;
            max-width: 380px;
            margin: 8px auto;
            padding: 12px;
            background: #12122a;
            border-radius: 10px;
            font-size: 0.8rem;
            color: #888;
            text-align: center;
            line-height: 1.6;
        }
    </style>
</head>
<body>

    <div class="header">
        <h1>SignVerse</h1>
        <p>التعرف على حروف لغة الإشارة العربية</p>
    </div>

    <div id="statusBar" class="status loading">جاري تحميل النموذج...</div>

    <div class="camera-box" id="cameraBox">
        <video id="video" autoplay playsinline></video>
    </div>

    <canvas id="canvas"></canvas>

    <div id="modeInfo" class="mode-info paused">التعرف التلقائي متوقف</div>

    <div class="result">
        <div id="resultLetter" class="result-letter">-</div>
        <div id="resultConfidence" class="result-confidence">فعل التعرف التلقائي وابدأ بالاشارة</div>
    </div>

    <div class="sentence-box">
        <div id="sentence" class="sentence-text"></div>
    </div>

    <div class="buttons">
        <button class="btn btn-auto paused" id="autoBtn" onclick="toggleAuto()">تشغيل التعرف</button>
        <button class="btn btn-add" id="addBtn" onclick="addLetter()">اضافة الحرف</button>
    </div>

    <div class="buttons">
        <button class="btn btn-clear" onclick="clearSentence()">مسح الكل</button>
        <button class="btn btn-delete" onclick="deleteLast()">حذف</button>
    </div>

    <div class="instructions">
        1. اضغط تشغيل التعرف لبدء التعرف التلقائي<br>
        2. اعمل اشارة الحرف بيدك امام الكاميرا<br>
        3. لما يظهر الحرف الصحيح اضغط اضافة الحرف<br>
    </div>

    <script>
        let model = null;
        let classNames = [];
        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d');
        let sentence = '';
        let autoMode = false;
        let autoInterval = null;
        let currentLetter = '';
        let currentConfidence = 0;

        async function startCamera() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({
                    video: { facingMode: 'environment', width: 224, height: 224 }
                });
                video.srcObject = stream;
                await video.play();
            } catch (err) {
                try {
                    const stream = await navigator.mediaDevices.getUserMedia({
                        video: { facingMode: 'user', width: 224, height: 224 }
                    });
                    video.srcObject = stream;
                    await video.play();
                } catch (err2) {
                    setStatus('خطأ في تشغيل الكاميرا', 'error');
                }
            }
        }

        // Fix Keras 3 model.json to work with TensorFlow.js
        function fixModelJson(json) {
            const str = JSON.stringify(json);
            // Replace batch_shape with batch_input_shape
            let fixed = str.replace(/"batch_shape"/g, '"batch_input_shape"');
            // Remove DTypePolicy objects and replace with simple string
            fixed = fixed.replace(/"dtype"\s*:\s*\{[^}]*"name"\s*:\s*"([^"]+)"[^}]*\}/g, '"dtype":"$1"');
            // Remove module/registered_name from initializers
            fixed = fixed.replace(/"module"\s*:\s*"[^"]*"\s*,\s*/g, '');
            fixed = fixed.replace(/,\s*"registered_name"\s*:\s*null/g, '');
            // Fix inbound_nodes format from Keras 3 to Keras 2
            let obj = JSON.parse(fixed);
            if (obj.modelTopology && obj.modelTopology.model_config) {
                const layers = obj.modelTopology.model_config.config.layers;
                for (let layer of layers) {
                    if (layer.inbound_nodes && layer.inbound_nodes.length > 0) {
                        const newNodes = [];
                        for (let node of layer.inbound_nodes) {
                            if (node.args) {
                                // Keras 3 format - convert to Keras 2
                                const args = Array.isArray(node.args) ? node.args : [node.args];
                                const connections = [];
                                for (let arg of args) {
                                    if (arg.class_name === '__keras_tensor__' && arg.config && arg.config.keras_history) {
                                        const h = arg.config.keras_history;
                                        connections.push([h[0], h[1], h[2], {}]);
                                    }
                                }
                                if (connections.length > 0) {
                                    newNodes.push(connections);
                                }
                            } else {
                                newNodes.push(node);
                            }
                        }
                        layer.inbound_nodes = newNodes;
                    }
                }
            }
            return obj;
        }

        async function loadModel() {
            try {
                setStatus('جاري تحميل النموذج...', 'loading');

                const classResponse = await fetch('class_names.json');
                classNames = await classResponse.json();

                // Load and fix model.json
                const modelResponse = await fetch('model.json');
                const modelJson = await modelResponse.json();
                const fixedJson = fixModelJson(modelJson);

                // Create a blob URL for the fixed model
                const fixedBlob = new Blob([JSON.stringify(fixedJson)], {type: 'application/json'});
                const fixedUrl = URL.createObjectURL(fixedBlob);

                // Custom IOHandler to load from blob + original shard files
                const modelUrl = new URL('model.json', window.location.href).href;
                const baseUrl = modelUrl.substring(0, modelUrl.lastIndexOf('/') + 1);

                model = await tf.loadLayersModel(tf.io.browserHTTPRequest(fixedUrl, {
                    fetchFunc: (url, init) => {
                        // If requesting the model.json, return our fixed version
                        if (url === fixedUrl || url.endsWith('model.json')) {
                            return fetch(fixedUrl);
                        }
                        // For weight files, fetch from original location
                        const filename = url.split('/').pop();
                        return fetch(baseUrl + filename);
                    }
                }));

                setStatus('النموذج جاهز!', 'ready');
            } catch (err) {
                // Try alternative loading method
                try {
                    setStatus('جاري المحاولة مرة اخرى...', 'loading');
                    
                    const classResponse = await fetch('class_names.json');
                    if (classNames.length === 0) {
                        classNames = await classResponse.json();
                    }

                    // Build model manually
                    model = tf.sequential();
                    model.add(tf.layers.conv2d({inputShape: [64, 64, 3], filters: 32, kernelSize: 3, activation: 'relu'}));
                    model.add(tf.layers.maxPooling2d({poolSize: 2}));
                    model.add(tf.layers.conv2d({filters: 64, kernelSize: 3, activation: 'relu'}));
                    model.add(tf.layers.maxPooling2d({poolSize: 2}));
                    model.add(tf.layers.conv2d({filters: 128, kernelSize: 3, activation: 'relu'}));
                    model.add(tf.layers.maxPooling2d({poolSize: 2}));
                    model.add(tf.layers.flatten());
                    model.add(tf.layers.dense({units: 256, activation: 'relu'}));
                    model.add(tf.layers.dropout({rate: 0.5}));
                    model.add(tf.layers.dense({units: 32, activation: 'softmax'}));

                    // Load weights
                    const baseUrl = window.location.href.substring(0, window.location.href.lastIndexOf('/') + 1);
                    const response = await fetch(baseUrl + 'model.json');
                    const modelJson = await response.json();
                    const weightPaths = modelJson.weightsManifest[0].paths;
                    const weightSpecs = modelJson.weightsManifest[0].weights;

                    // Fetch all weight files
                    const buffers = [];
                    for (const path of weightPaths) {
                        const resp = await fetch(baseUrl + path);
                        const buf = await resp.arrayBuffer();
                        buffers.push(buf);
                    }

                    // Combine buffers
                    const totalLength = buffers.reduce((acc, buf) => acc + buf.byteLength, 0);
                    const combined = new Uint8Array(totalLength);
                    let offset = 0;
                    for (const buf of buffers) {
                        combined.set(new Uint8Array(buf), offset);
                        offset += buf.byteLength;
                    }

                    // Create tensors from weight specs
                    const weightData = combined.buffer;
                    let byteOffset = 0;
                    const namedTensors = {};
                    for (const spec of weightSpecs) {
                        const size = spec.shape.reduce((a, b) => a * b, 1);
                        const byteSize = size * 4; // float32
                        const values = new Float32Array(weightData, byteOffset, size);
                        namedTensors[spec.name] = tf.tensor(Array.from(values), spec.shape);
                        byteOffset += byteSize;
                    }

                    // Map weights to layers
                    const layerWeights = [
                        [namedTensors['sequential/conv2d/kernel'], namedTensors['sequential/conv2d/bias']],
                        [], // maxpool
                        [namedTensors['sequential/conv2d_1/kernel'], namedTensors['sequential/conv2d_1/bias']],
                        [], // maxpool
                        [namedTensors['sequential/conv2d_2/kernel'], namedTensors['sequential/conv2d_2/bias']],
                        [], // maxpool
                        [], // flatten
                        [namedTensors['sequential/dense/kernel'], namedTensors['sequential/dense/bias']],
                        [], // dropout
                        [namedTensors['sequential/dense_1/kernel'], namedTensors['sequential/dense_1/bias']]
                    ];

                    for (let i = 0; i < model.layers.length; i++) {
                        if (layerWeights[i] && layerWeights[i].length > 0) {
                            model.layers[i].setWeights(layerWeights[i]);
                        }
                    }

                    setStatus('النموذج جاهز!', 'ready');
                } catch (err2) {
                    setStatus('خطأ في تحميل النموذج: ' + err2.message, 'error');
                    console.error(err2);
                }
            }
        }

        async function predict() {
            if (!model) return;

            canvas.width = 64;
            canvas.height = 64;
            ctx.drawImage(video, 0, 0, 64, 64);

            let tensor = tf.browser.fromPixels(canvas)
                .toFloat()
                .div(255.0)
                .expandDims(0);

            const prediction = model.predict(tensor);
            const probabilities = await prediction.data();
            const maxIndex = probabilities.indexOf(Math.max(...probabilities));
            const confidence = (probabilities[maxIndex] * 100).toFixed(1);
            const letter = classNames[maxIndex];

            currentLetter = letter;
            currentConfidence = probabilities[maxIndex];

            document.getElementById('resultLetter').textContent = letter;
            document.getElementById('resultConfidence').textContent = confidence + '%';

            const box = document.getElementById('cameraBox');
            if (currentConfidence > 0.7) {
                box.classList.add('detecting');
            } else {
                box.classList.remove('detecting');
            }

            tensor.dispose();
            prediction.dispose();
        }

        function toggleAuto() {
            autoMode = !autoMode;
            const btn = document.getElementById('autoBtn');
            const info = document.getElementById('modeInfo');

            if (autoMode) {
                btn.textContent = 'ايقاف التعرف';
                btn.classList.remove('paused');
                info.textContent = 'التعرف التلقائي شغال...';
                info.classList.remove('paused');
                autoInterval = setInterval(predict, 500);
            } else {
                btn.textContent = 'تشغيل التعرف';
                btn.classList.add('paused');
                info.textContent = 'التعرف التلقائي متوقف';
                info.classList.add('paused');
                document.getElementById('cameraBox').classList.remove('detecting');
                clearInterval(autoInterval);
            }
        }

        function addLetter() {
            if (currentLetter && currentConfidence > 0.3) {
                sentence += currentLetter;
                document.getElementById('sentence').textContent = sentence;
            }
        }

        function clearSentence() {
            sentence = '';
            document.getElementById('sentence').textContent = '';
            document.getElementById('resultLetter').textContent = '-';
            document.getElementById('resultConfidence').textContent = '';
        }

        function deleteLast() {
            sentence = sentence.slice(0, -1);
            document.getElementById('sentence').textContent = sentence;
        }

        function setStatus(text, type) {
            const bar = document.getElementById('statusBar');
            bar.textContent = text;
            bar.className = 'status ' + type;
        }

        async function init() {
            await startCamera();
            await loadModel();
        }

        init();
    </script>
</body>
</html>
